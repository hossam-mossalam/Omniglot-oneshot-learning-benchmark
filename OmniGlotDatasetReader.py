from scipy import misc
import numpy as np
import os
import random

class OmniGlotDatasetReader:
  '''
  OmniGlotDatasetReader class.

  Reads omni-glot images from given train and evaluation directories and
  generates training/evaluation batches.
  '''

  def __init__(self, train_directories,
               evaluation_directories):
    self.train_directories = train_directories
    self.evaluation_directories = evaluation_directories
    self.train_datasets = []
    self.evaluation_datasets = []
    self.build_datasets(train_directories, self.train_datasets)
    self.build_datasets(evaluation_directories, self.evaluation_datasets)

  def build_datasets(self, directories, dataset):
    ''' Datasets are loaded into train/evaluation directories. '''
    original_dir = os.getcwd()
    for dir_ in directories:
      os.chdir(dir_)
      for language in os.listdir():
        os.chdir(language)
        for character in os.listdir():
          os.chdir(character)
          current_dataset = []
          for img in os.listdir():
            # Images are scaled to be 20 x 20.
            current_dataset.append(misc.imresize(misc.imread(img),
                                                 (20, 20))/255.)
          dataset.append(current_dataset)
          os.chdir('../')
        os.chdir('../')
      os.chdir(original_dir)

  def generate_single_sequence(self, num_classes = 5, sequence_length = 100,
                               training = True):
    '''
    Generates a input/output sequence of elements from num_classes different
    classes.

    Args:
    num_classes: num of datasets to sample from when generating a sequence.
    sequence_length: number of elements in the sequence.
    training: picks either training or evaluation dataset to sample elements
        from.

    Returns:
    sequence: the sequence containing elements sampled from the datasets with
        each element concatinated with the one hot encoding of the correct
        label of the previous element
    output_one_hot: the sequence containing the one hot encoding of the correct
        labelling of each element in sequence.
    '''

    datasets = self.train_datasets if training else self.evaluation_datasets
    dataset_indices = random.sample(range(len(datasets)), num_classes)
    class_labels = np.random.permutation(num_classes)
    examples_per_class = sequence_length // num_classes
    sequence = []
    output = []

    for index, label in zip(dataset_indices, class_labels):
      current_dataset = datasets[index]
      current_size = min(len(current_dataset), examples_per_class)
      sequence += [np.random.permutation(current_dataset)[:current_size]]
      output += ([label] * current_size)

    sequence = np.array(sequence).reshape((sequence_length, -1))
    output = np.array(output)

    shuffle_indices = np.random.permutation(len(output))
    sequence = sequence[shuffle_indices]
    output = output[shuffle_indices]

    output_one_hot = np.zeros((sequence_length, num_classes))
    output_one_hot[np.arange(len(output)),output] = 1

    # constructing the proper input
    temp = np.concatenate((np.zeros((1, num_classes)),
        output_one_hot[:-1]), axis = 0)
    sequence = np.concatenate((sequence, temp), axis = 1)

    return sequence, output_one_hot

  def generate_batch(self, batch_size = 32, num_classes = 5,
                     sequence_length = 100, training = True):
    ''' Generates a batch of sequences generated by generate_single_sequence.'''
    batch = []
    output = []
    for _ in range(batch_size):
      new_batch, new_labels = self.generate_single_sequence(num_classes,
                                                            sequence_length,
                                                            training)
      batch.append(new_batch)
      output.append(new_labels)
    batch = np.array(batch)
    output = np.array(output)
    return batch, output

